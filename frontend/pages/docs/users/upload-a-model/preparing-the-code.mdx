import DocsWrapper from 'src/docs/DocsWrapper'

# Preparing the Code

In addition to the model card, Bailo expects every upload to come with a `code` and `binary` file. These files contain
the supporting code and binary data respectively.

## Binary

The `binary` file contains your models vectors or data. This is a model specific format and has no requirements beyond
being uploaded as a compressed `.zip` file. This is the model that is generated through training, which may be generated
internally or imported as an open source or commercially acquired pre-trained model.

There are no restrictions on the framework used to generate the model, but details of the training approach and training
data should be provided within the associated model card.

The model binary is loaded into a model class provided by the supporting model code and is included in the image
generated by Bailo. When this image is deployed within a target environment it exposes a set of endpoints, one of which
is the predict endpoint that's used to retrieve the model's results.

The binary `.zip` folder is extracted to the root working directory, the same location that the code file is extracted
to.

## Code

As a model contributor you must develop your model code in Python and structure it in accordance with the guidelines
laid out on this page. This includes making use of a template model class, which has the benefit of providing
consistency with respect to the code structure, but avoids imposing unnecessary restrictions. At present, this class
must be present in your codebase but the intention is to make it available for import as an external library.

The `code` file should be a compressed `.zip` file with the following file structure:

```txt
code.zip/
├─ Model.py
├─ requirements.txt
└─ basemodel/
   ├─ basemodel.py
   └─ __init__.py
```

- `model.py`: discussed under the [Model Wrapper](./model-wrapper) section.
- `requirements.txt`: is a standard dependency file, explained in detail by
  [PyPa](https://pip.pypa.io/en/stable/reference/requirements-file-format/).
- `basemodel.py` & `__init__.py`: is an abstract class to help you implement the requirement functions.

We provide a basemodel class that contains the functions:

- predict
- metrics
- metadata

As a model contributor, you need to import this and use it as a super class to your model code and, at minimum,
instantiate the predict method in order to create a valid model. This approach allows you to test your model code
externally, while ensuring minimal integration work is required when submitting the model to Bailo.

The basemodel can be found [here](../examples/example_model_code/basemodel/basemodel.py), but the contents are also
provided below for easy reference.

**\_\_init\_\_.py**

```python
from .basemodel import BaseModel
```

**basemodel.py**

```python
# basemodel.py
from abc import ABC, abstractmethod


class BaseModel(ABC):
    """
    The BaseModel class provides an abstract template for model contributors.
    Models must provide a predict method but do not have to provide metrics or metadata
    """

    def __init__(self):
        """
        The model should be loaded here in the Model sub-class generated
        from the BaseModel abstract class

        Example:
            self.model = load_model("model")
        """
        super().__init__()

    def predict(self, input, features_names):
        """
        Provides a model prediction for a given input and set of feature names
        :param input: Prediction input containing a data component
        :param feature_names: Optional set of feature names
        :return: JSON serialisable numpy array, list of values, string or bytes

        Example:
            data = input["data"]
            result = self.model.predict(data)
            return result
        """
        pass

    def metrics(self):
        """
        Optional method for adding additional metrics
        :return:

        Example:
            return an array of metrics tuples
            metrics =  [{"type": "COUNTER", "key": "metric_1", "value": 1}]
            return metrics
        """
        pass

    def metadata(self):
        """
        Optional metadata method.
        :return:

        Example:
            meta = {"field": "value"}
            return meta
        """
        pass
```

**Example - model.py**

```python
import fasttext
import numpy as np
import json

from basemodel import BaseModel

    class Model(BaseModel):
        """
        This class loads the FastText lid.176.bin language ID model.
        It instantiates the predict abstract method from the BaseModel class
        and overwrites the metrics method.
        """

        def __init__(self):
            """
            Constructor, which loads the lid model and calls the constructor method
            of the BaseModel super class.
            """
            self.model = fasttext.load_model("lid.176.bin")

        def predict(self, input, features_names=None):
            """
            Generate a prediction from the model given the specified input data and feature names.
            :param input: Dictionary containing a data key with a text value
            :param feature_names: Set of feature names to be applied (not used in this model)
            :return: Dictionary containing an array of predictions and an array of probabilities
            """
            data = input["data"]
            (self.predictions, probabilities) = self.model.predict(data)
            self.probabilities = [float(p) for p in probabilities]

            # Need to convert probabilities from ndarry to floats, as cant serialize numpy objects
            # We can't rely on the order of these being maintained. This needs to be corrected.
            return {"predictions": self.predictions, "probabilites": self.probabilities}

        def metrics(self):
            """
            Generate model metrics for prediction count and metadata.
            :return: Array of dictionary tuples
            """
            # Add metrics for prediction count and metadata
            metrics =  [
              {"type": "COUNTER", "key": "predictions_total", "value": 1},
              {"type": "GAUGE", "key": "model_meta", "value": 1}
            ]
            # Track confidence metrics
            for i in range(len(self.predictions)):
                metrics.append(
                    {
                        "type": "GAUGE",
                        "key": "prediction_confidence_{}".format(self.predictions[i][0]),
                        "value": self.probabilities[i]
                    }
                )
            return metrics
```

The current approach does not specify the allowable return types from the model's predict method prior to wrapping.
However, the return type must be json serializable and this may present difficulties where the type returned is complex
or contains non-serializable types (such as numpy floats within dictionaries or arrays within dictionaries).

As a model contributor you must therefore perform any necessary conversions to ensure that the output of the predict
method is json serialisable. This includes external models, such as those available from opensource or commercially
acquired. In these cases you will need to perform the necessary conversion in the model class but this will not impact
on the acquired model itself.

export default ({ children }) => <DocsWrapper>{children}</DocsWrapper>
